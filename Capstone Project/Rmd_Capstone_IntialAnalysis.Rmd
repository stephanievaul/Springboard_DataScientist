---
title: "Capstone: Initial Aanalysis on BMW Sales trends in the US"
author: "Stephanie Vaul"
output: html_document
---


```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```


## Introduction

I'm going to analyze the BMW automotive sales trends in the USA over the last 10 years in order to determine which areas of the country and which models display the highest sales volume and repeat ownership (brand loyalty). In addition, I will try to identify first-time BMW owners and see which model appeal most to them. I will also look at how these trends vary between New and Used vehicles.  

My client is BMW North America, a company that my employer has partnered with over the last 10 years to provide customer retention marketing. Determining which model series do well in each geographic area, as well as which series result in repeat buyers will help BMW better focus their marketing efforts for various ad campaigns by leveraging existing trends, as well as being able to extrapolate those trends in other areas of similar makeup.  

I plan to use dealership sales data that my company has been collecting for the past 10+ years in order to provide sales-to-service retention marketing, e.g. initial service reminders. This data includes customer and vehicle information, along with the purchase date and type (new vs used). Some of the data includes demographic information, like birthdate and gender. I will review the data to see if there is sufficient data in order to provide trend reports based on age &/or gender.  

Proprietary sales data from most BMW centers in the U.S. going back 10yrs:

•Region (BMW Region assigned to the selling dealership by BMW, of which there are four)
•Market (BMW Market assigned to the selling dealership by BMW)
•PurchDate
•VehYear
•VehModel
•VehECode (engine code assigned by BMW to categorize years & models)
•TradeVIN
•TradeVehYear
•TradeVehModel
•TradeVehECode
•NewUsed (New, Used, Other sale)
•PurchType (Lease, Cash, Finance)
•Gender (limited data provided here)

BMW also has their own designations for dealership Region and Market. I will apply this similar sorting parameters to the customer’s address in order to determine which Region a customer belongs too. 
Because we also collect service data, I will be able to also look at how long a customer owned a vehicle by reviewing both Sales and Service data. I will first look to see if we have subsequent sales data on the vehicle – whether that be from another customer purchasing the VIN or the VIN being listed by the same customer as being traded in. If there is no additional sales record, then I can turn to the service history to see when they last serviced it. While this is not entirely accurate should the customer service at an independent station, it will provide better information than not having it at all.  

My approach will be to first segment the customers into the various BMW regions, possibly down to the Market level. Their markets are based on BMW locations so this might not be to be extrapolated correctly to all customers. I will then segment out the purchases by model series and type (new or used). I want to be able to see a count of each model series and type for each year overall and within each region. Once top-level exploratory analysis has been performed, I’ll start looking into more details on customer loyalty based on repeat purchases and try to identify which are made by first-time buyers. After that, I will look to see if I can pinpoint the length of ownership for each vehicle to be able to summarize which series are kept by a single owner the longest. 


## The Data Set

To get started, let’s set our working directory, clear our Environment, & load our libraries.

<!-- # Working Directory -->
```{r directory}
setwd("~/_MyFiles/Data Science Workshop/Springboard_DataScientist/Capstone Project")
getwd()
```

<!-- ## Review Environment and clear it -->
```{r enviroment}
  rm(list=ls())
  ls()
```

<!-- ## Load Libraries -->
```{r libraries}
library(devtools)
library(stringr)
library(tidyr)
library(dplyr)
```

Now let's read in our data set, which contains both BMW Dealership data, as well as customer and vehicle sales data over the past 10-years. 
<!-- read.table ("BMWSales.txt", header = TRUE, sep = "|", quote = "\"", nrows = 500) -->

```{r readdata}
Sales <- read.table ("BMWSales.txt", header = TRUE, sep = "|", quote = "\"", stringsAsFactors = FALSE)     
```


```{r summarySales}
summary(Sales)
``` 
```{r headSales, echo = FALSE}
#head(Sales)     
```

Let's subset this data to eliminate any sales at non-BMW dealerships and remove unnecessary fields. 

```{r subset}
SalesSub <- subset(Sales, BMWDlr=="True", select = c(BMWRegion, BMWMarket, DealerID, DealerState, VINID, VIN, Year, Make, Model, eCode, PurchDate, NewUsed, PayType, FinanceTerm, PurchasePrice, TradeVINID, TradeVIN, TradeYear, TradeMake, TradeModel, TradeECode, CustID, CustState, Gender, BirthDate) )
```

```{r headsub}
head(SalesSub)     
```
```{r summarysub}
summary(SalesSub)     
```


We need to set PurchDate, along FinanceTerm and Birthdate, to a date field before we can use it to reduce the subset to a 10 year window between 1/1/2007 and 12/31/2016. Since SQL data comes with milliseconds, we need to use the following POSIXct format: 

```{r date}
SalesSub$PurchDate <- as.POSIXct(SalesSub$PurchDate, format = "%Y-%m-%d %H:%M:%OS")
SalesSub$FinanceTerm <- as.POSIXct(SalesSub$FinanceTerm, format = "%Y-%m-%d %H:%M:%OS")
SalesSub$BirthDate <- as.POSIXct(SalesSub$BirthDate, format = "%Y-%m-%d %H:%M:%OS")
```
<!-- SalesSub$NewPurchDate <- NULL -->

Now we can go back up and recheck our Head &/or Summary to see that the fields are correctly set as datetime. Since they are, let’s go ahead and drop the original Sales table:
```{r removeSales}
rm(Sales)
```


From here we can use the PurchDate to further subset our data. In this case, let’s just replace the SalesSub table.
```{r subset2}
SalesSub <- subset(SalesSub, as.POSIXct(PurchDate)>=as.POSIXct('2007-01-01 00:00:00.000') & as.POSIXct(PurchDate)<as.POSIXct('2017-01-01 00:00:00.000'), select = c(BMWRegion, BMWMarket, DealerID, DealerState, VINID, VIN, Year, Make, Model, eCode, PurchDate, NewUsed, PayType, FinanceTerm, PurchasePrice, TradeVINID, TradeVIN, TradeYear, TradeMake, TradeModel, TradeECode, CustID, CustState, Gender, BirthDate) )
```

If we check our summary again, we can see the new PurchDate range.
```{r summarysub2}
summary(SalesSub)     
```

Before moving on, let’s convert this data.frame into a dplyr table.
```{r converttotbl}
tbl_df(SalesSub)
```

<!-- Create Backup SalesSub <- NULL -->
```{r Backup, echo = FALSE}
SalesSub2 <- SalesSub
```


Let’s take a closer look at some of the other fields to see if anything needs to be corrected before we move on to the data analysis.

BMW Region
<!-- # distinct(select(SalesSub,BMWRegion)) -->
```{r RegionReview}
SalesSub %>% 
    group_by(BMWRegion) %>% 
    summarise(cnt = n())
```

We see that there were different cases, all CAPS mostly and some mixed, used for the Regions. Let’s set those all to CAPS. We can go back up and recheck our summary when done.


We also saw from the Summary that there were different cases, all CAPS mostly and some mixed, used for the Regions. Let's set those all to CAPS. 
```{r RegionToUpper}
SalesSub$BMWRegion <- toupper(SalesSub$BMWRegion)     
```


Gender
```{r GenderReview}
SalesSub %>% 
    group_by(Gender) %>% 
    summarise(Cnt = n()) %>%  
    arrange(desc(Cnt))
```

While we may not be able to effectively utilize the Gender variable due to most records missing this field, let’s go ahead and normalize it as well. We can set all the values of just M to MALE and just F to FEMALE.
```{r GenderNormalizing}
SalesSub$Gender <- gsub('^M$', 'MALE', SalesSub$Gender)
SalesSub$Gender <- gsub('^F$', 'FEMALE', SalesSub$Gender)
```

Once this is complete, we need to remove all the invalid data.
```{r GenderRemoveInvalids}
SalesSub$Gender <- ifelse ( grepl("FEMALE|MALE", SalesSub$Gender), SalesSub$Gender, '' )

SalesSub %>% 
    group_by(Gender) %>% 
    summarise(Cnt = n())
```

If we decide to use CustState, we’ll want to set all to Upper and then remove or fix any that are not part of the 51 US states or military codes, such as AE, AP, etc. For now, we can ignore this field.

Similarly for model Year, if we decide to utilize this field, we’ll need to change any 2-digit years to 4-digit years and possibly exclude those that are missing or invalid.

Let’s take another look at our data to see if we need to clean up any additional fields at this time.

```{r ReviewAgain}
head(SalesSub)

SalesSub %>% 
    group_by(BMWMarket) %>% 
    summarise(Cnt = n())

SalesSub %>% 
    group_by(DealerState) %>% 
    summarise(Cnt = n())

SalesSub %>% 
    group_by(Model) %>% 
    summarise(Cnt = n())

SalesSub %>% 
    group_by(eCode) %>% 
    summarise(Cnt = n(), MinYr = min(Year), MaxYr = max(Year))

SalesSub %>% 
    group_by(PayType) %>% 
    summarise(Cnt = n())

SalesSub %>% 
    group_by(NewUsed) %>% 
    summarise(Cnt = n())
```



# Left off here....



#Pitfalls of the data set

* Not all BMW stores have provided access to their Sales data so the analysis is limited by dealership participation.  
* Due to possible changes in the system that a dealer uses to manage their database, the customerID's can change over time. This means that a single customer may actually have more than one CustomerID and be seen as 2 or more unique customers. More elaborate customer matching, based on name & address, could be done to try to remedy some of these issue, but there is still room for error based on how a name or address is typed into the system. For example, "Jim" vs "James" or "1234 Main Street" vs "1234 Main St.". We will also not see if the same customer purchases as more than one BMW dealership.  
* And, finally, we are not going to see all sales made to all non-BMW dealerships as well as private sales. These can skew the model by not reflecting the proper length of ownership.